{"cells": [{"metadata": {"trusted": true}, "cell_type": "code", "source": "import pandas as pd\nimport numpy as np\nimport io\n#import os\n#import tensorflow as tf\nfrom PIL import Image\nfrom tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras import Model\nfrom pyspark.sql.functions import col, pandas_udf, PandasUDFType, element_at, split\nfrom typing import Iterator\nimport time\nfrom pyspark.sql.functions import udf\nfrom pyspark.ml.linalg import Vectors, VectorUDT\nfrom pyspark.ml.feature import PCA", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "Starting Spark application\n", "name": "stdout"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<table>\n<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>1</td><td>application_1674288775996_0002</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-32-116.eu-west-3.compute.internal:20888/proxy/application_1674288775996_0002/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-43-226.eu-west-3.compute.internal:8042/node/containerlogs/container_1674288775996_0002_01_000001/livy\">Link</a></td><td>\u2714</td></tr></table>"}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "SparkSession available as 'spark'.\n", "name": "stdout"}, {"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def load_data(PATH_Data):\n  \"\"\"\n  Load the data in binary files\n  \"\"\"\n  # Load images using Spark's binary file data source. You could alternatively use Spark's image data source, but the binary file data source provides more flexibility in how you preprocess images.\n  start_time = time.time()\n  images = spark.read.format(\"binaryFile\") \\\n  .option(\"pathGlobFilter\", \"*.jpg\") \\\n  .option(\"recursiveFileLookup\", \"true\") \\\n  .load(PATH_Data)\n  print(\"Temps d'execution {:.2f} secondes\".format(time.time() - start_time))\n  return images\n\ndef get_labels(images):\n  \"\"\"\n  Add a column label to the dataframe spark\n  \"\"\"\n  start_time = time.time()\n  images = images.withColumn('label', element_at(split(images['path'], '/'),-2))\n  print(\"Temps d'execution {:.2f} secondes\".format(time.time() - start_time))\n  return images\n\ndef get_broadcast_weights():\n  \"\"\" \n  Returns the broadcasted weights of a MobileNetV2 with top layer removed\n  \"\"\"\n  start_time = time.time()\n  model = MobileNetV2(weights='imagenet',\n                    include_top=True,\n                    input_shape=(224, 224, 3))\n  new_model = Model(inputs=model.input,\n                  outputs=model.layers[-2].output)\n  broadcast_weights = spark.sparkContext.broadcast(new_model.get_weights())\n  print(\"Temps d'execution {:.2f} secondes\".format(time.time() - start_time))\n  return broadcast_weights\n\ndef model_fn():\n    \"\"\"\n    Returns a MobileNetV2 model with top layer removed \n    and broadcasted pretrained weights.\n    \"\"\"\n    model = MobileNetV2(weights='imagenet',\n                        include_top=True,\n                        input_shape=(224, 224, 3))\n    for layer in model.layers:\n        layer.trainable = False\n    new_model = Model(inputs=model.input,\n                  outputs=model.layers[-2].output)\n    new_model.set_weights(broadcast_weights.value)\n    return new_model\n\ndef preprocess(content):\n    \"\"\"\n    Preprocesses raw image bytes for prediction.\n    \"\"\"\n    img = Image.open(io.BytesIO(content)).resize([224, 224])\n    arr = img_to_array(img)\n    return preprocess_input(arr)\n\ndef featurize_series(model, content_series):\n    \"\"\"\n    Featurize a pd.Series of raw images using the input model.\n    :return: a pd.Series of image features\n    \"\"\"\n    input = np.stack(content_series.map(preprocess))\n    preds = model.predict(input)\n    # For some layers, output features will be multi-dimensional tensors.\n    # We flatten the feature tensors to vectors for easier storage in Spark DataFrames.\n    output = [p.flatten() for p in preds]\n    return pd.Series(output)\n\n@pandas_udf('array<float>')\ndef featurize_udf(content_series_iter: Iterator[pd.Series]) -> Iterator[pd.Series]:\n    '''\n    This method is a Scalar Iterator pandas UDF wrapping our featurization function.\n    The decorator specifies that this returns a Spark DataFrame column of type ArrayType(FloatType).\n\n    :param content_series_iter: This argument is an iterator over batches of data, where each batch\n                              is a pandas Series of image data.\n    '''\n    # With Scalar Iterator pandas UDFs, we can load the model once and then re-use it\n    # for multiple data batches.  This amortizes the overhead of loading big models.\n    \n    model = model_fn()\n    for content_series in content_series_iter:\n        yield featurize_series(model, content_series)\n\ndef pca_transform(df, n_components = 20):\n  start_time = time.time()\n  # Les donn\u00e9es images sont converties au format vecteur dense\n  ud_f = udf(lambda r: Vectors.dense(r), VectorUDT())\n  df = df.withColumn('features', ud_f('features'))\n\n  pca = PCA(k=10, inputCol='features', outputCol='pca_features')\n  model = pca.fit(df)\n  df = model.transform(df)\n\n  print(\"Temps d'execution {:.2f} secondes\".format(time.time() - start_time))\n  return df\n\ndef save_results(df, path):\n  start_time = time.time()\n  df.write.mode(\"overwrite\").parquet(path)\n  print(\"Temps d'execution {:.2f} secondes\".format(time.time() - start_time))", "execution_count": 2, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "start_time_full = time.time()\n\nPATH = 's3://ma-projet8'\nPATH_Data = PATH+'/images'\nPATH_Results = PATH+'/Results'\n\nprint(\"-----Loading data-----\")\n\nimages = load_data(PATH_Data)\nprint(\"-----Get labels-----\")\nimages = get_labels(images)\n\nprint(\"-----Broadcast the weights of the model-----\")\nbroadcast_weights = get_broadcast_weights()\n\nprint(\"-----Apply featurization to the DataFrame of images----- \")\nstart_time = time.time()\nfeatures_df = images.repartition(24).select(col(\"path\"),\n                                        col(\"label\"),\n                                        featurize_udf(\"content\").alias(\"features\")\n                                       )\nprint(\"Temps d'execution {:.2f} secondes\".format(time.time() - start_time))\n\nprint(\"-----PCA on the features-----\")\nfeatures_df = pca_transform(features_df, n_components = 80)\n\ndf_final = features_df.select(col(\"path\"), col(\"label\"),col(\"pca_features\"))\nprint(\"-----Saving the results-----\")\nsave_results(df_final,PATH_Results)\n\nfull_time = time.time() - start_time_full\nprint(\"Ex\u00e9cution total pour\", images.count(), \"images :\", full_time, \"secondes\" )", "execution_count": 3, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "-----Loading data-----\nTemps d'execution 11.45 secondes\n-----Get labels-----\nTemps d'execution 0.34 secondes\n-----Broadcast the weights of the model-----\nTemps d'execution 1.75 secondes\n-----Apply featurization to the DataFrame of images----- \nTemps d'execution 0.23 secondes\n-----PCA on the features-----\nTemps d'execution 139.23 secondes\n-----Saving the results-----\nTemps d'execution 66.80 secondes\nEx\u00e9cution total pour 573 images : 219.82818984985352 secondes", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "pysparkkernel", "display_name": "PySpark", "language": ""}, "language_info": {"name": "pyspark", "mimetype": "text/x-python", "codemirror_mode": {"name": "python", "version": 3}, "pygments_lexer": "python3"}}, "nbformat": 4, "nbformat_minor": 4}